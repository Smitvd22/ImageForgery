{
  "test_timestamp": "2025-08-18T14:29:04.906116",
  "best_model": "random_forest",
  "best_metrics": {
    "accuracy": 0.9696969696969697,
    "precision": 0.9714795008912657,
    "recall": 0.9696969696969697,
    "f1_score": 0.9696969696969697,
    "precision_per_class": [
      1.0,
      0.9411764705882353
    ],
    "recall_per_class": [
      0.9411764705882353,
      1.0
    ],
    "f1_per_class": [
      0.9696969696969697,
      0.9696969696969697
    ],
    "roc_auc": 1.0,
    "average_precision": 1.0,
    "confusion_matrix": [
      [
        16,
        1
      ],
      [
        0,
        16
      ]
    ],
    "true_negatives": 16,
    "false_positives": 1,
    "false_negatives": 0,
    "true_positives": 16,
    "specificity": 0.9411764705882353,
    "sensitivity": 1.0,
    "false_positive_rate": 0.058823529411764705,
    "false_negative_rate": 0.0,
    "classification_report": {
      "Authentic": {
        "precision": 1.0,
        "recall": 0.9411764705882353,
        "f1-score": 0.9696969696969697,
        "support": 17.0
      },
      "Forged": {
        "precision": 0.9411764705882353,
        "recall": 1.0,
        "f1-score": 0.9696969696969697,
        "support": 16.0
      },
      "accuracy": 0.9696969696969697,
      "macro avg": {
        "precision": 0.9705882352941176,
        "recall": 0.9705882352941176,
        "f1-score": 0.9696969696969697,
        "support": 33.0
      },
      "weighted avg": {
        "precision": 0.9714795008912657,
        "recall": 0.9696969696969697,
        "f1-score": 0.9696969696969697,
        "support": 33.0
      }
    },
    "prediction_time": 0.11780929565429688,
    "predictions_per_second": 280.11371952206713
  },
  "all_results": {
    "xgboost": {
      "accuracy": 0.9393939393939394,
      "precision": 0.9461279461279462,
      "recall": 0.9393939393939394,
      "f1_score": 0.9392825311942959,
      "precision_per_class": [
        1.0,
        0.8888888888888888
      ],
      "recall_per_class": [
        0.8823529411764706,
        1.0
      ],
      "f1_per_class": [
        0.9375,
        0.9411764705882353
      ],
      "roc_auc": 0.9963235294117647,
      "average_precision": 0.9963235294117647,
      "confusion_matrix": [
        [
          15,
          2
        ],
        [
          0,
          16
        ]
      ],
      "true_negatives": 15,
      "false_positives": 2,
      "false_negatives": 0,
      "true_positives": 16,
      "specificity": 0.8823529411764706,
      "sensitivity": 1.0,
      "false_positive_rate": 0.11764705882352941,
      "false_negative_rate": 0.0,
      "classification_report": {
        "Authentic": {
          "precision": 1.0,
          "recall": 0.8823529411764706,
          "f1-score": 0.9375,
          "support": 17.0
        },
        "Forged": {
          "precision": 0.8888888888888888,
          "recall": 1.0,
          "f1-score": 0.9411764705882353,
          "support": 16.0
        },
        "accuracy": 0.9393939393939394,
        "macro avg": {
          "precision": 0.9444444444444444,
          "recall": 0.9411764705882353,
          "f1-score": 0.9393382352941176,
          "support": 33.0
        },
        "weighted avg": {
          "precision": 0.9461279461279462,
          "recall": 0.9393939393939394,
          "f1-score": 0.9392825311942959,
          "support": 33.0
        }
      },
      "prediction_time": 0.0018994808197021484,
      "predictions_per_second": 17373.168319317185
    },
    "lightgbm": {
      "accuracy": 0.5151515151515151,
      "precision": 0.26538108356290174,
      "recall": 0.5151515151515151,
      "f1_score": 0.35030303030303034,
      "precision_per_class": [
        0.5151515151515151,
        0.0
      ],
      "recall_per_class": [
        1.0,
        0.0
      ],
      "f1_per_class": [
        0.68,
        0.0
      ],
      "roc_auc": 0.5,
      "average_precision": 0.48484848484848486,
      "confusion_matrix": [
        [
          17,
          0
        ],
        [
          16,
          0
        ]
      ],
      "true_negatives": 17,
      "false_positives": 0,
      "false_negatives": 16,
      "true_positives": 0,
      "specificity": 1.0,
      "sensitivity": 0.0,
      "false_positive_rate": 0.0,
      "false_negative_rate": 1.0,
      "classification_report": {
        "Authentic": {
          "precision": 0.5151515151515151,
          "recall": 1.0,
          "f1-score": 0.68,
          "support": 17.0
        },
        "Forged": {
          "precision": 0.0,
          "recall": 0.0,
          "f1-score": 0.0,
          "support": 16.0
        },
        "accuracy": 0.5151515151515151,
        "macro avg": {
          "precision": 0.25757575757575757,
          "recall": 0.5,
          "f1-score": 0.34,
          "support": 33.0
        },
        "weighted avg": {
          "precision": 0.26538108356290174,
          "recall": 0.5151515151515151,
          "f1-score": 0.35030303030303034,
          "support": 33.0
        }
      },
      "prediction_time": 1.4485480785369873,
      "predictions_per_second": 22.781432310710407
    },
    "random_forest": {
      "accuracy": 0.9696969696969697,
      "precision": 0.9714795008912657,
      "recall": 0.9696969696969697,
      "f1_score": 0.9696969696969697,
      "precision_per_class": [
        1.0,
        0.9411764705882353
      ],
      "recall_per_class": [
        0.9411764705882353,
        1.0
      ],
      "f1_per_class": [
        0.9696969696969697,
        0.9696969696969697
      ],
      "roc_auc": 1.0,
      "average_precision": 1.0,
      "confusion_matrix": [
        [
          16,
          1
        ],
        [
          0,
          16
        ]
      ],
      "true_negatives": 16,
      "false_positives": 1,
      "false_negatives": 0,
      "true_positives": 16,
      "specificity": 0.9411764705882353,
      "sensitivity": 1.0,
      "false_positive_rate": 0.058823529411764705,
      "false_negative_rate": 0.0,
      "classification_report": {
        "Authentic": {
          "precision": 1.0,
          "recall": 0.9411764705882353,
          "f1-score": 0.9696969696969697,
          "support": 17.0
        },
        "Forged": {
          "precision": 0.9411764705882353,
          "recall": 1.0,
          "f1-score": 0.9696969696969697,
          "support": 16.0
        },
        "accuracy": 0.9696969696969697,
        "macro avg": {
          "precision": 0.9705882352941176,
          "recall": 0.9705882352941176,
          "f1-score": 0.9696969696969697,
          "support": 33.0
        },
        "weighted avg": {
          "precision": 0.9714795008912657,
          "recall": 0.9696969696969697,
          "f1-score": 0.9696969696969697,
          "support": 33.0
        }
      },
      "prediction_time": 0.11780929565429688,
      "predictions_per_second": 280.11371952206713
    },
    "extra_trees": {
      "accuracy": 0.9696969696969697,
      "precision": 0.9714795008912657,
      "recall": 0.9696969696969697,
      "f1_score": 0.9696969696969697,
      "precision_per_class": [
        1.0,
        0.9411764705882353
      ],
      "recall_per_class": [
        0.9411764705882353,
        1.0
      ],
      "f1_per_class": [
        0.9696969696969697,
        0.9696969696969697
      ],
      "roc_auc": 1.0,
      "average_precision": 1.0,
      "confusion_matrix": [
        [
          16,
          1
        ],
        [
          0,
          16
        ]
      ],
      "true_negatives": 16,
      "false_positives": 1,
      "false_negatives": 0,
      "true_positives": 16,
      "specificity": 0.9411764705882353,
      "sensitivity": 1.0,
      "false_positive_rate": 0.058823529411764705,
      "false_negative_rate": 0.0,
      "classification_report": {
        "Authentic": {
          "precision": 1.0,
          "recall": 0.9411764705882353,
          "f1-score": 0.9696969696969697,
          "support": 17.0
        },
        "Forged": {
          "precision": 0.9411764705882353,
          "recall": 1.0,
          "f1-score": 0.9696969696969697,
          "support": 16.0
        },
        "accuracy": 0.9696969696969697,
        "macro avg": {
          "precision": 0.9705882352941176,
          "recall": 0.9705882352941176,
          "f1-score": 0.9696969696969697,
          "support": 33.0
        },
        "weighted avg": {
          "precision": 0.9714795008912657,
          "recall": 0.9696969696969697,
          "f1-score": 0.9696969696969697,
          "support": 33.0
        }
      },
      "prediction_time": 0.09150362014770508,
      "predictions_per_second": 360.64146912145577
    },
    "mlp": {
      "accuracy": 0.8787878787878788,
      "precision": 0.8848484848484849,
      "recall": 0.8787878787878788,
      "f1_score": 0.8785650623885918,
      "precision_per_class": [
        0.9333333333333333,
        0.8333333333333334
      ],
      "recall_per_class": [
        0.8235294117647058,
        0.9375
      ],
      "f1_per_class": [
        0.875,
        0.8823529411764706
      ],
      "roc_auc": 0.9669117647058824,
      "average_precision": 0.9641316597489198,
      "confusion_matrix": [
        [
          14,
          3
        ],
        [
          1,
          15
        ]
      ],
      "true_negatives": 14,
      "false_positives": 3,
      "false_negatives": 1,
      "true_positives": 15,
      "specificity": 0.8235294117647058,
      "sensitivity": 0.9375,
      "false_positive_rate": 0.17647058823529413,
      "false_negative_rate": 0.0625,
      "classification_report": {
        "Authentic": {
          "precision": 0.9333333333333333,
          "recall": 0.8235294117647058,
          "f1-score": 0.875,
          "support": 17.0
        },
        "Forged": {
          "precision": 0.8333333333333334,
          "recall": 0.9375,
          "f1-score": 0.8823529411764706,
          "support": 16.0
        },
        "accuracy": 0.8787878787878788,
        "macro avg": {
          "precision": 0.8833333333333333,
          "recall": 0.8805147058823529,
          "f1-score": 0.8786764705882353,
          "support": 33.0
        },
        "weighted avg": {
          "precision": 0.8848484848484849,
          "recall": 0.8787878787878788,
          "f1-score": 0.8785650623885918,
          "support": 33.0
        }
      },
      "prediction_time": 0.0005104541778564453,
      "predictions_per_second": 64648.31013545072
    },
    "voting_ensemble": {
      "accuracy": 0.9696969696969697,
      "precision": 0.9714795008912657,
      "recall": 0.9696969696969697,
      "f1_score": 0.9696969696969697,
      "precision_per_class": [
        1.0,
        0.9411764705882353
      ],
      "recall_per_class": [
        0.9411764705882353,
        1.0
      ],
      "f1_per_class": [
        0.9696969696969697,
        0.9696969696969697
      ],
      "roc_auc": 1.0,
      "average_precision": 1.0,
      "confusion_matrix": [
        [
          16,
          1
        ],
        [
          0,
          16
        ]
      ],
      "true_negatives": 16,
      "false_positives": 1,
      "false_negatives": 0,
      "true_positives": 16,
      "specificity": 0.9411764705882353,
      "sensitivity": 1.0,
      "false_positive_rate": 0.058823529411764705,
      "false_negative_rate": 0.0,
      "classification_report": {
        "Authentic": {
          "precision": 1.0,
          "recall": 0.9411764705882353,
          "f1-score": 0.9696969696969697,
          "support": 17.0
        },
        "Forged": {
          "precision": 0.9411764705882353,
          "recall": 1.0,
          "f1-score": 0.9696969696969697,
          "support": 16.0
        },
        "accuracy": 0.9696969696969697,
        "macro avg": {
          "precision": 0.9705882352941176,
          "recall": 0.9705882352941176,
          "f1-score": 0.9696969696969697,
          "support": 33.0
        },
        "weighted avg": {
          "precision": 0.9714795008912657,
          "recall": 0.9696969696969697,
          "f1-score": 0.9696969696969697,
          "support": 33.0
        }
      },
      "prediction_time": 0.23721528053283691,
      "predictions_per_second": 139.11414106998018
    }
  },
  "dataset_info": {
    "sample_count": 33,
    "feature_count": 4517
  },
  "system_info": {
    "gpu_used": true,
    "gpu_name": "NVIDIA GeForce RTX 3050 6GB Laptop GPU",
    "device": "cuda"
  },
  "total_test_time": 33.562803983688354
}